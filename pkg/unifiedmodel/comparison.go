// Package unifiedmodel comparison provides production-ready schema comparison functions.
// This module implements comprehensive comparison logic with field-level granularity,
// performance optimization, and database-aware intelligence for schema change detection.

package unifiedmodel

import (
	"crypto/sha256"
	"encoding/json"
	"fmt"
	"strings"
	"time"
)

// Enhanced comparison options for production use
type EnhancedComparisonOptions struct {
	ComparisonOptions

	// Field-level control
	IgnoreFields      []string           `json:"ignore_fields,omitempty"`    // e.g., ["comment", "last_updated"]
	CompareTimestamps bool               `json:"compare_timestamps"`         // Whether to compare timestamp fields
	ToleranceFields   map[string]float64 `json:"tolerance_fields,omitempty"` // Tolerance for numeric fields

	// Performance optimization
	EnableEarlyExit  bool `json:"enable_early_exit"`  // Stop on first difference for fast checks
	MaxDiffCount     int  `json:"max_diff_count"`     // Limit number of differences tracked
	EnableFieldCache bool `json:"enable_field_cache"` // Cache field reflection info

	// Schema-specific options
	CompareColumnOrder    bool `json:"compare_column_order"`    // Whether column order matters
	CompareIndexOrder     bool `json:"compare_index_order"`     // Whether index order matters
	IgnoreAutoGenerated   bool `json:"ignore_auto_generated"`   // Ignore auto-generated fields
	CompareConstraintDefs bool `json:"compare_constraint_defs"` // Compare constraint definitions
}

// DefaultEnhancedComparisonOptions returns production-optimized comparison options
func DefaultEnhancedComparisonOptions() EnhancedComparisonOptions {
	return EnhancedComparisonOptions{
		ComparisonOptions:     DefaultComparisonOptions(),
		IgnoreFields:          []string{"comment", "last_updated", "created_at", "modified_at"},
		CompareTimestamps:     false,
		EnableEarlyExit:       false,
		MaxDiffCount:          1000, // Prevent memory issues with massive schemas
		EnableFieldCache:      true,
		CompareColumnOrder:    false, // Usually not significant for compatibility
		CompareIndexOrder:     false,
		IgnoreAutoGenerated:   true,
		CompareConstraintDefs: true,
		ToleranceFields: map[string]float64{
			"size_bytes": 0.01, // 1% tolerance for size estimates
		},
	}
}

// FastComparisonOptions returns options optimized for quick change detection
func FastComparisonOptions() EnhancedComparisonOptions {
	opts := DefaultEnhancedComparisonOptions()
	opts.EnableEarlyExit = true
	opts.MaxDiffCount = 1
	return opts
}

// CompareTablesDetailed performs detailed table-to-table comparison
func CompareTablesDetailed(source, target Table, options EnhancedComparisonOptions) []StructuralChange {
	var changes []StructuralChange

	// Compare basic table properties
	if source.Name != target.Name {
		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  ObjectTypeTable,
			ObjectPath:  fmt.Sprintf("tables.%s.name", source.Name),
			SourceValue: &source.Name,
			TargetValue: &target.Name,
			Description: fmt.Sprintf("Table renamed from %s to %s", source.Name, target.Name),
			Severity:    ChangeSeverityCritical,
			IsBreaking:  true,
		})
	}

	if !shouldIgnoreField("comment", options.IgnoreFields) && source.Comment != target.Comment {
		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  ObjectTypeTable,
			ObjectPath:  fmt.Sprintf("tables.%s.comment", source.Name),
			SourceValue: &source.Comment,
			TargetValue: &target.Comment,
			Description: "Table comment changed",
			Severity:    ChangeSeverityMinor,
			IsBreaking:  false,
		})
	}

	// Compare columns with detailed analysis
	columnChanges := compareColumnsDetailed(source.Columns, target.Columns, source.Name, options)
	changes = append(changes, columnChanges...)

	// Compare indexes
	indexChanges := compareIndexesDetailed(source.Indexes, target.Indexes, source.Name, options)
	changes = append(changes, indexChanges...)

	// Compare constraints
	constraintChanges := compareConstraintsDetailed(source.Constraints, target.Constraints, source.Name, options)
	changes = append(changes, constraintChanges...)

	// Early exit if requested and changes found
	if options.EnableEarlyExit && len(changes) > 0 {
		return changes[:1] // Return only first change
	}

	// Limit diff count to prevent memory issues
	if options.MaxDiffCount > 0 && len(changes) > options.MaxDiffCount {
		changes = changes[:options.MaxDiffCount]
		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  ObjectTypeTable,
			ObjectPath:  fmt.Sprintf("tables.%s", source.Name),
			Description: fmt.Sprintf("Too many changes detected (>%d), comparison truncated", options.MaxDiffCount),
			Severity:    ChangeSeverityMajor,
			IsBreaking:  false,
		})
	}

	return changes
}

// compareColumnsDetailed performs detailed column comparison
func compareColumnsDetailed(source, target map[string]Column, tableName string, options EnhancedComparisonOptions) []StructuralChange {
	var changes []StructuralChange

	// Track column order changes if requested
	if options.CompareColumnOrder {
		sourceOrder := getColumnOrder(source)
		targetOrder := getColumnOrder(target)
		if !sliceEqual(sourceOrder, targetOrder) {
			changes = append(changes, StructuralChange{
				ChangeType:  ChangeTypeModified,
				ObjectType:  ObjectTypeTable,
				ObjectPath:  fmt.Sprintf("tables.%s.columns.order", tableName),
				Description: "Column order changed",
				Severity:    ChangeSeverityMinor,
				IsBreaking:  false,
			})
		}
	}

	// Find added columns
	for name, column := range target {
		if _, exists := source[name]; !exists {
			severity := ChangeSeverityMajor
			isBreaking := false

			// Adding non-nullable columns without defaults is breaking
			if !column.Nullable && column.Default == "" && !column.AutoIncrement {
				severity = ChangeSeverityCritical
				isBreaking = true
			}

			changes = append(changes, StructuralChange{
				ChangeType:  ChangeTypeAdded,
				ObjectType:  ObjectTypeTable,
				ObjectPath:  fmt.Sprintf("tables.%s.columns.%s", tableName, name),
				TargetValue: stringPtr(fmt.Sprintf("%s %s", column.Name, column.DataType)),
				Description: fmt.Sprintf("Added column %s (%s)", name, column.DataType),
				Severity:    severity,
				IsBreaking:  isBreaking,
			})
		}
	}

	// Find removed columns
	for name, column := range source {
		if _, exists := target[name]; !exists {
			changes = append(changes, StructuralChange{
				ChangeType:  ChangeTypeRemoved,
				ObjectType:  ObjectTypeTable,
				ObjectPath:  fmt.Sprintf("tables.%s.columns.%s", tableName, name),
				SourceValue: stringPtr(fmt.Sprintf("%s %s", column.Name, column.DataType)),
				Description: fmt.Sprintf("Removed column %s (%s)", name, column.DataType),
				Severity:    ChangeSeverityCritical,
				IsBreaking:  true,
			})
		}
	}

	// Find modified columns
	for name := range source {
		if targetColumn, exists := target[name]; exists {
			sourceColumn := source[name]
			columnChanges := compareColumnProperties(sourceColumn, targetColumn, tableName, name, options)
			changes = append(changes, columnChanges...)
		}
	}

	return changes
}

// compareColumnProperties performs detailed property-by-property column comparison
func compareColumnProperties(source, target Column, tableName, columnName string, options EnhancedComparisonOptions) []StructuralChange {
	var changes []StructuralChange
	basePath := fmt.Sprintf("tables.%s.columns.%s", tableName, columnName)

	// Data type changes
	if source.DataType != target.DataType {
		severity := determineDataTypeChangeSeverity(source.DataType, target.DataType)
		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  ObjectTypeTable,
			ObjectPath:  basePath + ".data_type",
			SourceValue: &source.DataType,
			TargetValue: &target.DataType,
			Description: fmt.Sprintf("Column %s data type changed from %s to %s", columnName, source.DataType, target.DataType),
			Severity:    severity,
			IsBreaking:  severity == ChangeSeverityCritical,
		})
	}

	// Nullable changes
	if source.Nullable != target.Nullable {
		severity := ChangeSeverityMajor
		isBreaking := false

		// Making a column non-nullable is potentially breaking
		if source.Nullable && !target.Nullable {
			severity = ChangeSeverityCritical
			isBreaking = true
		}

		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  ObjectTypeTable,
			ObjectPath:  basePath + ".nullable",
			SourceValue: stringPtr(fmt.Sprintf("%t", source.Nullable)),
			TargetValue: stringPtr(fmt.Sprintf("%t", target.Nullable)),
			Description: fmt.Sprintf("Column %s nullable changed from %t to %t", columnName, source.Nullable, target.Nullable),
			Severity:    severity,
			IsBreaking:  isBreaking,
		})
	}

	// Default value changes
	if source.Default != target.Default {
		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  ObjectTypeTable,
			ObjectPath:  basePath + ".default",
			SourceValue: &source.Default,
			TargetValue: &target.Default,
			Description: fmt.Sprintf("Column %s default value changed", columnName),
			Severity:    ChangeSeverityMajor,
			IsBreaking:  false,
		})
	}

	// Primary key changes
	if source.IsPrimaryKey != target.IsPrimaryKey {
		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  ObjectTypeTable,
			ObjectPath:  basePath + ".is_primary_key",
			SourceValue: stringPtr(fmt.Sprintf("%t", source.IsPrimaryKey)),
			TargetValue: stringPtr(fmt.Sprintf("%t", target.IsPrimaryKey)),
			Description: fmt.Sprintf("Column %s primary key status changed", columnName),
			Severity:    ChangeSeverityCritical,
			IsBreaking:  true,
		})
	}

	// Auto increment changes
	if source.AutoIncrement != target.AutoIncrement {
		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  ObjectTypeTable,
			ObjectPath:  basePath + ".auto_increment",
			SourceValue: stringPtr(fmt.Sprintf("%t", source.AutoIncrement)),
			TargetValue: stringPtr(fmt.Sprintf("%t", target.AutoIncrement)),
			Description: fmt.Sprintf("Column %s auto increment changed", columnName),
			Severity:    ChangeSeverityMajor,
			IsBreaking:  false,
		})
	}

	return changes
}

// compareIndexesDetailed performs detailed index comparison
func compareIndexesDetailed(source, target map[string]Index, tableName string, options EnhancedComparisonOptions) []StructuralChange {
	var changes []StructuralChange

	// Find added indexes
	for name, index := range target {
		if _, exists := source[name]; !exists {
			changes = append(changes, StructuralChange{
				ChangeType:  ChangeTypeAdded,
				ObjectType:  "index",
				ObjectPath:  fmt.Sprintf("tables.%s.indexes.%s", tableName, name),
				TargetValue: stringPtr(fmt.Sprintf("%s (%s)", index.Name, strings.Join(index.Columns, ", "))),
				Description: fmt.Sprintf("Added index %s on columns [%s]", name, strings.Join(index.Columns, ", ")),
				Severity:    ChangeSeverityMinor,
				IsBreaking:  false,
			})
		}
	}

	// Find removed indexes
	for name, index := range source {
		if _, exists := target[name]; !exists {
			// Removing unique indexes is more severe
			severity := ChangeSeverityMinor
			if index.Unique {
				severity = ChangeSeverityMajor
			}

			changes = append(changes, StructuralChange{
				ChangeType:  ChangeTypeRemoved,
				ObjectType:  "index",
				ObjectPath:  fmt.Sprintf("tables.%s.indexes.%s", tableName, name),
				SourceValue: stringPtr(fmt.Sprintf("%s (%s)", index.Name, strings.Join(index.Columns, ", "))),
				Description: fmt.Sprintf("Removed index %s", name),
				Severity:    severity,
				IsBreaking:  false,
			})
		}
	}

	// Find modified indexes
	for name := range source {
		if targetIndex, exists := target[name]; exists {
			sourceIndex := source[name]
			indexChanges := compareIndexProperties(sourceIndex, targetIndex, tableName, name, options)
			changes = append(changes, indexChanges...)
		}
	}

	return changes
}

// compareIndexProperties compares individual index properties
func compareIndexProperties(source, target Index, tableName, indexName string, options EnhancedComparisonOptions) []StructuralChange {
	var changes []StructuralChange
	basePath := fmt.Sprintf("tables.%s.indexes.%s", tableName, indexName)

	// Compare columns
	if !sliceEqual(source.Columns, target.Columns) {
		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  "index",
			ObjectPath:  basePath + ".columns",
			SourceValue: stringPtr(strings.Join(source.Columns, ", ")),
			TargetValue: stringPtr(strings.Join(target.Columns, ", ")),
			Description: fmt.Sprintf("Index %s columns changed", indexName),
			Severity:    ChangeSeverityMajor,
			IsBreaking:  false,
		})
	}

	// Compare uniqueness
	if source.Unique != target.Unique {
		severity := ChangeSeverityMajor
		isBreaking := false

		// Making an index unique is potentially breaking
		if !source.Unique && target.Unique {
			severity = ChangeSeverityCritical
			isBreaking = true
		}

		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  "index",
			ObjectPath:  basePath + ".unique",
			SourceValue: stringPtr(fmt.Sprintf("%t", source.Unique)),
			TargetValue: stringPtr(fmt.Sprintf("%t", target.Unique)),
			Description: fmt.Sprintf("Index %s uniqueness changed", indexName),
			Severity:    severity,
			IsBreaking:  isBreaking,
		})
	}

	// Compare index type
	if source.Type != target.Type {
		changes = append(changes, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  "index",
			ObjectPath:  basePath + ".type",
			SourceValue: stringPtr(string(source.Type)),
			TargetValue: stringPtr(string(target.Type)),
			Description: fmt.Sprintf("Index %s type changed from %s to %s", indexName, source.Type, target.Type),
			Severity:    ChangeSeverityMajor,
			IsBreaking:  false,
		})
	}

	return changes
}

// compareConstraintsDetailed performs detailed constraint comparison
func compareConstraintsDetailed(source, target map[string]Constraint, tableName string, options EnhancedComparisonOptions) []StructuralChange {
	var changes []StructuralChange

	// Find added constraints
	for name, constraint := range target {
		if _, exists := source[name]; !exists {
			severity := ChangeSeverityMajor
			isBreaking := false

			// Adding certain constraints can be breaking
			if constraint.Type == ConstraintTypeNotNull || constraint.Type == ConstraintTypeCheck {
				severity = ChangeSeverityCritical
				isBreaking = true
			}

			changes = append(changes, StructuralChange{
				ChangeType:  ChangeTypeAdded,
				ObjectType:  "constraint",
				ObjectPath:  fmt.Sprintf("tables.%s.constraints.%s", tableName, name),
				TargetValue: stringPtr(fmt.Sprintf("%s (%s)", constraint.Name, constraint.Type)),
				Description: fmt.Sprintf("Added %s constraint %s", constraint.Type, name),
				Severity:    severity,
				IsBreaking:  isBreaking,
			})
		}
	}

	// Find removed constraints
	for name, constraint := range source {
		if _, exists := target[name]; !exists {
			severity := ChangeSeverityMajor
			isBreaking := false

			// Removing primary key or foreign key constraints is breaking
			if constraint.Type == ConstraintTypePrimaryKey || constraint.Type == ConstraintTypeForeignKey {
				severity = ChangeSeverityCritical
				isBreaking = true
			}

			changes = append(changes, StructuralChange{
				ChangeType:  ChangeTypeRemoved,
				ObjectType:  "constraint",
				ObjectPath:  fmt.Sprintf("tables.%s.constraints.%s", tableName, name),
				SourceValue: stringPtr(fmt.Sprintf("%s (%s)", constraint.Name, constraint.Type)),
				Description: fmt.Sprintf("Removed %s constraint %s", constraint.Type, name),
				Severity:    severity,
				IsBreaking:  isBreaking,
			})
		}
	}

	return changes
}

// Helper functions

func shouldIgnoreField(fieldName string, ignoreFields []string) bool {
	for _, ignored := range ignoreFields {
		if fieldName == ignored {
			return true
		}
	}
	return false
}

func getColumnOrder(columns map[string]Column) []string {
	var order []string
	for name := range columns {
		order = append(order, name)
	}
	return order
}

func sliceEqual(a, b []string) bool {
	if len(a) != len(b) {
		return false
	}
	for i := range a {
		if a[i] != b[i] {
			return false
		}
	}
	return true
}

func determineDataTypeChangeSeverity(sourceType, targetType string) ChangeSeverity {
	// Simplified logic - in practice, this would need comprehensive type compatibility rules

	// Same type family changes (e.g., varchar(100) -> varchar(200)) are less severe
	sourceBase := strings.Split(sourceType, "(")[0]
	targetBase := strings.Split(targetType, "(")[0]

	if sourceBase == targetBase {
		return ChangeSeverityMajor
	}

	// Check for compatible type changes
	compatibleChanges := map[string][]string{
		"int":     {"bigint", "decimal"},
		"varchar": {"text"},
		"float":   {"double", "decimal"},
	}

	if compatible, exists := compatibleChanges[sourceBase]; exists {
		for _, compatType := range compatible {
			if targetBase == compatType {
				return ChangeSeverityMajor
			}
		}
	}

	// Most type changes are potentially breaking
	return ChangeSeverityCritical
}

// EnhancedCompareSchemas provides production-ready schema comparison with detailed analysis
func EnhancedCompareSchemas(source, target *UnifiedModel, options EnhancedComparisonOptions) (*ComparisonResult, error) {
	if source == nil || target == nil {
		return nil, fmt.Errorf("both source and target schemas must be non-nil")
	}

	result := &ComparisonResult{
		SourceSchema:   GenerateSchemaID(source),
		TargetSchema:   GenerateSchemaID(target),
		ComparedAt:     time.Now(),
		ComparisonMode: options.Mode,
	}

	var allChanges []StructuralChange

	// Compare database type
	if source.DatabaseType != target.DatabaseType {
		allChanges = append(allChanges, StructuralChange{
			ChangeType:  ChangeTypeModified,
			ObjectType:  "database_type",
			ObjectPath:  "database_type",
			SourceValue: stringPtr(string(source.DatabaseType)),
			TargetValue: stringPtr(string(target.DatabaseType)),
			Description: fmt.Sprintf("Database type changed from %s to %s", source.DatabaseType, target.DatabaseType),
			Severity:    ChangeSeverityCritical,
			IsBreaking:  true,
		})
	}

	// Compare tables with detailed analysis
	for name, sourceTable := range source.Tables {
		if targetTable, exists := target.Tables[name]; exists {
			// Table exists in both - detailed comparison
			tableChanges := CompareTablesDetailed(sourceTable, targetTable, options)
			allChanges = append(allChanges, tableChanges...)
		} else {
			// Table removed
			allChanges = append(allChanges, StructuralChange{
				ChangeType:  ChangeTypeRemoved,
				ObjectType:  ObjectTypeTable,
				ObjectPath:  fmt.Sprintf("tables.%s", name),
				SourceValue: &name,
				Description: fmt.Sprintf("Removed table %s", name),
				Severity:    ChangeSeverityCritical,
				IsBreaking:  true,
			})
		}

		// Early exit if requested
		if options.EnableEarlyExit && len(allChanges) > 0 {
			break
		}
	}

	// Find added tables
	if !options.EnableEarlyExit || len(allChanges) == 0 {
		for name := range target.Tables {
			if _, exists := source.Tables[name]; !exists {
				allChanges = append(allChanges, StructuralChange{
					ChangeType:  ChangeTypeAdded,
					ObjectType:  ObjectTypeTable,
					ObjectPath:  fmt.Sprintf("tables.%s", name),
					TargetValue: &name,
					Description: fmt.Sprintf("Added table %s", name),
					Severity:    ChangeSeverityMajor,
					IsBreaking:  false,
				})
			}
		}
	}

	// Apply max diff limit
	if options.MaxDiffCount > 0 && len(allChanges) > options.MaxDiffCount {
		allChanges = allChanges[:options.MaxDiffCount]
	}

	result.StructuralChanges = allChanges
	result.HasStructuralChanges = len(allChanges) > 0
	result.StructuralSimilarity = calculateStructuralSimilarity(source, target, allChanges)
	result.OverallSimilarity = result.StructuralSimilarity
	result.CompatibilityScore = calculateCompatibilityScore(allChanges)
	result.MigrationComplexity = determineMigrationComplexity(allChanges)

	return result, nil
}

// CompareSchemas is the main entry point for schema comparison.
// It provides both basic and enhanced comparison modes based on options.
func CompareSchemas(source, target *UnifiedModel, options ComparisonOptions) (*ComparisonResult, error) {
	// Convert to enhanced options with defaults
	enhancedOptions := EnhancedComparisonOptions{
		ComparisonOptions:     options,
		IgnoreFields:          []string{"comment", "last_updated", "created_at"},
		CompareTimestamps:     false,
		EnableEarlyExit:       false,
		MaxDiffCount:          1000,
		EnableFieldCache:      true,
		CompareColumnOrder:    false,
		CompareIndexOrder:     false,
		IgnoreAutoGenerated:   true,
		CompareConstraintDefs: true,
	}

	return EnhancedCompareSchemas(source, target, enhancedOptions)
}

// HasSignificantChanges checks if two schemas have changes that would require versioning.
// This is used by the unified model service to determine if a new version should be created.
func HasSignificantChanges(source, target *UnifiedModel) (bool, error) {
	if source == nil && target == nil {
		return false, nil
	}
	if source == nil || target == nil {
		return true, nil // One is nil, definitely significant
	}

	// Quick hash comparison first
	sourceHash := GenerateSchemaHash(source)
	targetHash := GenerateSchemaHash(target)

	if sourceHash == targetHash {
		return false, nil // Identical schemas
	}

	// Perform fast comparison to check for structural changes
	options := FastComparisonOptions()
	result, err := EnhancedCompareSchemas(source, target, options)
	if err != nil {
		return false, fmt.Errorf("comparison failed: %w", err)
	}

	// Consider changes significant if they affect structure
	return result.HasStructuralChanges, nil
}

// GenerateSchemaID generates a unique identifier for a schema based on its content.
// This ID is used to link schemas to their metrics and enrichment data.
func GenerateSchemaID(schema *UnifiedModel) string {
	if schema == nil {
		return ""
	}

	hash := GenerateSchemaHash(schema)
	// Use first 16 characters of hash for readability
	return fmt.Sprintf("schema-%s", hash[:16])
}

// GenerateSchemaHash generates a SHA-256 hash of the schema structure.
// This is used for quick equality checks and change detection.
func GenerateSchemaHash(schema *UnifiedModel) string {
	if schema == nil {
		return ""
	}

	// Create a normalized representation for hashing
	normalized := normalizeForHashing(schema)

	// Convert to JSON for stable hashing
	jsonBytes, err := json.Marshal(normalized)
	if err != nil {
		// Fallback to string representation
		jsonBytes = []byte(fmt.Sprintf("%+v", normalized))
	}

	// Generate SHA-256 hash
	hash := sha256.Sum256(jsonBytes)
	return fmt.Sprintf("%x", hash)
}

// ValidateSchema validates a UnifiedModel schema for consistency and completeness.
// This ensures the schema is valid before storage or comparison.
func ValidateSchema(schema *UnifiedModel) []ValidationError {
	var errors []ValidationError

	if schema == nil {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorCritical,
			Field:      "schema",
			Message:    "schema cannot be nil",
			Suggestion: "provide a valid UnifiedModel instance",
		})
		return errors
	}

	// Validate database type
	if schema.DatabaseType == "" {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorCritical,
			Field:      "database_type",
			Message:    "database_type is required",
			Suggestion: "set database_type to a valid database technology",
		})
	}

	// Validate that at least one data container exists
	totalDataContainers := len(schema.Tables) + len(schema.Collections) +
		len(schema.Nodes) + len(schema.Views) + len(schema.MaterializedViews)

	if totalDataContainers == 0 {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorWarning,
			Field:      "data_containers",
			Message:    "no data containers found (tables, collections, nodes, views)",
			Suggestion: "add at least one table, collection, node, or view",
		})
	}

	// Validate table structures
	for tableName, table := range schema.Tables {
		tableErrors := validateTable(tableName, table)
		errors = append(errors, tableErrors...)
	}

	// Validate collection structures
	for collectionName, collection := range schema.Collections {
		collectionErrors := validateCollection(collectionName, collection)
		errors = append(errors, collectionErrors...)
	}

	// Validate constraints reference valid objects
	for constraintName, constraint := range schema.Constraints {
		constraintErrors := validateConstraint(constraintName, constraint, schema)
		errors = append(errors, constraintErrors...)
	}

	// Validate indexes reference valid objects
	for indexName, index := range schema.Indexes {
		indexErrors := validateIndex(indexName, index, schema)
		errors = append(errors, indexErrors...)
	}

	return errors
}

// IsSchemaEmpty checks if a schema contains any meaningful data.
func IsSchemaEmpty(schema *UnifiedModel) bool {
	if schema == nil {
		return true
	}

	// Check if any data containers exist
	totalObjects := len(schema.Tables) + len(schema.Collections) + len(schema.Nodes) +
		len(schema.Views) + len(schema.MaterializedViews) + len(schema.Functions) +
		len(schema.Procedures) + len(schema.Indexes) + len(schema.Constraints)

	return totalObjects == 0
}

// CloneSchema creates a deep copy of a UnifiedModel schema.
// This is useful for creating modified versions without affecting the original.
func CloneSchema(schema *UnifiedModel) (*UnifiedModel, error) {
	if schema == nil {
		return nil, nil
	}

	// Use JSON marshaling/unmarshaling for deep copy
	jsonBytes, err := json.Marshal(schema)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal schema: %w", err)
	}

	var cloned UnifiedModel
	err = json.Unmarshal(jsonBytes, &cloned)
	if err != nil {
		return nil, fmt.Errorf("failed to unmarshal schema: %w", err)
	}

	return &cloned, nil
}

// MergeSchemas combines two schemas, with the target schema taking precedence.
// This is useful for applying incremental updates to schemas.
func MergeSchemas(base, overlay *UnifiedModel) (*UnifiedModel, error) {
	if base == nil && overlay == nil {
		return nil, nil
	}
	if base == nil {
		return CloneSchema(overlay)
	}
	if overlay == nil {
		return CloneSchema(base)
	}

	// Start with a copy of the base schema
	merged, err := CloneSchema(base)
	if err != nil {
		return nil, fmt.Errorf("failed to clone base schema: %w", err)
	}

	// Apply overlay values
	if overlay.DatabaseType != "" {
		merged.DatabaseType = overlay.DatabaseType
	}

	// Merge maps (overlay takes precedence)
	mergeSchemaObjects(merged.Tables, overlay.Tables)
	mergeSchemaObjects(merged.Collections, overlay.Collections)
	mergeSchemaObjects(merged.Nodes, overlay.Nodes)
	mergeSchemaObjects(merged.Views, overlay.Views)
	mergeSchemaObjects(merged.MaterializedViews, overlay.MaterializedViews)
	mergeSchemaObjects(merged.Indexes, overlay.Indexes)
	mergeSchemaObjects(merged.Constraints, overlay.Constraints)
	mergeSchemaObjects(merged.Functions, overlay.Functions)
	mergeSchemaObjects(merged.Procedures, overlay.Procedures)
	mergeSchemaObjects(merged.Triggers, overlay.Triggers)
	mergeSchemaObjects(merged.Sequences, overlay.Sequences)
	mergeSchemaObjects(merged.Types, overlay.Types)
	mergeSchemaObjects(merged.Users, overlay.Users)
	mergeSchemaObjects(merged.Roles, overlay.Roles)
	mergeSchemaObjects(merged.Grants, overlay.Grants)
	mergeSchemaObjects(merged.Policies, overlay.Policies)

	return merged, nil
}

// ValidationError represents a validation issue found in a schema
type ValidationError struct {
	Type       ValidationErrorType `json:"type"`
	Field      string              `json:"field"`
	Message    string              `json:"message"`
	Suggestion string              `json:"suggestion,omitempty"`
}

type ValidationErrorType string

const (
	ValidationErrorCritical ValidationErrorType = "critical" // Prevents schema usage
	ValidationErrorWarning  ValidationErrorType = "warning"  // Potentially problematic
	ValidationErrorInfo     ValidationErrorType = "info"     // Informational
)

// Helper functions for the newly added functions

func normalizeForHashing(schema *UnifiedModel) *UnifiedModel {
	// Create a copy for normalization
	normalized, _ := CloneSchema(schema)
	if normalized == nil {
		return nil
	}

	// Sort maps by keys for stable hashing
	// JSON marshaling will handle map key sorting automatically
	return normalized
}

func validateTable(tableName string, table Table) []ValidationError {
	var errors []ValidationError

	if table.Name == "" {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorCritical,
			Field:      fmt.Sprintf("tables.%s.name", tableName),
			Message:    "table name cannot be empty",
			Suggestion: "set a valid table name",
		})
	}

	if len(table.Columns) == 0 {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorWarning,
			Field:      fmt.Sprintf("tables.%s.columns", tableName),
			Message:    "table has no columns",
			Suggestion: "add at least one column to the table",
		})
	}

	// Validate column names are unique
	columnNames := make(map[string]bool)
	for colName := range table.Columns {
		if columnNames[colName] {
			errors = append(errors, ValidationError{
				Type:       ValidationErrorCritical,
				Field:      fmt.Sprintf("tables.%s.columns.%s", tableName, colName),
				Message:    fmt.Sprintf("duplicate column name: %s", colName),
				Suggestion: "ensure all column names are unique within the table",
			})
		}
		columnNames[colName] = true
	}

	return errors
}

func validateCollection(collectionName string, collection Collection) []ValidationError {
	var errors []ValidationError

	if collection.Name == "" {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorCritical,
			Field:      fmt.Sprintf("collections.%s.name", collectionName),
			Message:    "collection name cannot be empty",
			Suggestion: "set a valid collection name",
		})
	}

	return errors
}

func validateConstraint(constraintName string, constraint Constraint, schema *UnifiedModel) []ValidationError {
	var errors []ValidationError

	if constraint.Name == "" {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorCritical,
			Field:      fmt.Sprintf("constraints.%s.name", constraintName),
			Message:    "constraint name cannot be empty",
			Suggestion: "set a valid constraint name",
		})
	}

	// Validate constraint type
	if constraint.Type == "" {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorCritical,
			Field:      fmt.Sprintf("constraints.%s.type", constraintName),
			Message:    "constraint type cannot be empty",
			Suggestion: "set a valid constraint type (primary_key, foreign_key, unique, check, etc.)",
		})
	}

	return errors
}

func validateIndex(indexName string, index Index, schema *UnifiedModel) []ValidationError {
	var errors []ValidationError

	if index.Name == "" {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorCritical,
			Field:      fmt.Sprintf("indexes.%s.name", indexName),
			Message:    "index name cannot be empty",
			Suggestion: "set a valid index name",
		})
	}

	if len(index.Columns) == 0 {
		errors = append(errors, ValidationError{
			Type:       ValidationErrorWarning,
			Field:      fmt.Sprintf("indexes.%s.columns", indexName),
			Message:    "index has no columns",
			Suggestion: "add at least one column to the index",
		})
	}

	return errors
}

func mergeSchemaObjects[T any](target, source map[string]T) {
	if source == nil {
		return
	}
	if target == nil {
		target = make(map[string]T)
	}

	for k, v := range source {
		target[k] = v
	}
}

func calculateStructuralSimilarity(source, target *UnifiedModel, changes []StructuralChange) float64 {
	if len(changes) == 0 {
		return 1.0 // Identical
	}

	// Simple similarity calculation based on number of changes relative to total objects
	sourceObjects := countTotalObjects(source)
	targetObjects := countTotalObjects(target)
	totalObjects := maxInt(sourceObjects, targetObjects)

	if totalObjects == 0 {
		return 1.0
	}

	// Weight changes by severity
	severityWeight := 0.0
	for _, change := range changes {
		switch change.Severity {
		case ChangeSeverityCritical:
			severityWeight += 1.0
		case ChangeSeverityMajor:
			severityWeight += 0.7
		case ChangeSeverityMinor:
			severityWeight += 0.3
		}
	}

	similarity := 1.0 - (severityWeight / float64(totalObjects))
	if similarity < 0 {
		similarity = 0
	}

	return similarity
}

func calculateCompatibilityScore(changes []StructuralChange) float64 {
	if len(changes) == 0 {
		return 1.0
	}

	breakingChanges := 0
	for _, change := range changes {
		if change.IsBreaking {
			breakingChanges++
		}
	}

	// Compatibility inversely related to breaking changes
	if breakingChanges == 0 {
		return 1.0
	}

	compatibility := 1.0 - (float64(breakingChanges) / float64(len(changes)))
	if compatibility < 0 {
		compatibility = 0
	}

	return compatibility
}

func determineMigrationComplexity(changes []StructuralChange) MigrationComplexity {
	if len(changes) == 0 {
		return MigrationComplexityNone
	}

	breakingChanges := 0
	criticalChanges := 0

	for _, change := range changes {
		if change.IsBreaking {
			breakingChanges++
		}
		if change.Severity == ChangeSeverityCritical {
			criticalChanges++
		}
	}

	if criticalChanges > 0 || breakingChanges > 5 {
		return MigrationComplexityHigh
	}
	if breakingChanges > 0 || len(changes) > 10 {
		return MigrationComplexityMedium
	}

	return MigrationComplexityLow
}

func countTotalObjects(schema *UnifiedModel) int {
	if schema == nil {
		return 0
	}

	return len(schema.Tables) + len(schema.Collections) + len(schema.Nodes) +
		len(schema.Views) + len(schema.MaterializedViews) + len(schema.Indexes) +
		len(schema.Constraints) + len(schema.Functions) + len(schema.Procedures) +
		len(schema.Triggers) + len(schema.Sequences) + len(schema.Types)
}

func maxInt(a, b int) int {
	if a > b {
		return a
	}
	return b
}

func stringPtr(s string) *string {
	return &s
}
